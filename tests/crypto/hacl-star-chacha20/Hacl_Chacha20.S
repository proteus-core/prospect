	.file	"Hacl_Chacha20.c"
	.option nopic
	.attribute arch, "rv32i2p0_m2p0"
	.attribute unaligned_access, 0
	.attribute stack_align, 16
	.text
	.align	2
	.type	double_round.constprop.0, @function
double_round.constprop.0:
	lui	a5,%hi(.LANCHOR0)
	addi	a5,a5,%lo(.LANCHOR0)
	lw	a0,20(a5)
	lw	a1,24(a5)
	lw	t5,4(a5)
	lw	t4,8(a5)
	lw	a7,52(a5)
	lw	a6,56(a5)
	addi	sp,sp,-32
	lw	a3,16(a5)
	lw	a2,28(a5)
	lw	t6,0(a5)
	add	t5,a0,t5
	add	t4,a1,t4
	lw	t3,12(a5)
	sw	s1,24(sp)
	lw	t1,48(a5)
	lw	a4,60(a5)
	lw	s1,40(a5)
	xor	a7,t5,a7
	xor	a6,t4,a6
	lw	t0,36(a5)
	sw	s3,16(sp)
	sw	s4,12(sp)
	slli	s3,a6,16
	slli	s4,a7,16
	srli	a6,a6,16
	srli	a7,a7,16
	add	t6,a3,t6
	add	t3,a2,t3
	or	a7,a7,s4
	or	a6,a6,s3
	sw	s0,28(sp)
	xor	t1,t6,t1
	lw	s0,44(a5)
	xor	a4,t3,a4
	add	t0,a7,t0
	add	s1,a6,s1
	lw	t2,32(a5)
	sw	s2,20(sp)
	sw	s5,8(sp)
	slli	s2,a4,16
	slli	s5,t1,16
	xor	a0,a0,t0
	xor	a1,a1,s1
	srli	t1,t1,16
	srli	a4,a4,16
	or	t1,t1,s5
	or	a4,a4,s2
	slli	s4,a0,12
	slli	s3,a1,12
	srli	a0,a0,20
	srli	a1,a1,20
	add	t2,t1,t2
	add	s0,a4,s0
	or	a0,a0,s4
	or	a1,a1,s3
	xor	a3,a3,t2
	xor	a2,a2,s0
	add	t5,t5,a0
	add	t4,t4,a1
	slli	s5,a3,12
	slli	s2,a2,12
	xor	a7,a7,t5
	xor	a6,a6,t4
	srli	a3,a3,20
	srli	a2,a2,20
	or	a3,a3,s5
	or	a2,a2,s2
	slli	s4,a7,8
	slli	s3,a6,8
	srli	a7,a7,24
	srli	a6,a6,24
	add	t6,t6,a3
	add	t3,t3,a2
	or	a7,a7,s4
	or	a6,a6,s3
	xor	t1,t1,t6
	xor	a4,a4,t3
	add	t0,t0,a7
	add	s1,s1,a6
	slli	s5,t1,8
	slli	s2,a4,8
	xor	a0,a0,t0
	xor	a1,a1,s1
	srli	t1,t1,24
	srli	a4,a4,24
	or	t1,t1,s5
	or	a4,a4,s2
	slli	s4,a0,7
	slli	s3,a1,7
	srli	a0,a0,25
	srli	a1,a1,25
	add	t2,t2,t1
	add	s0,s0,a4
	or	a0,a0,s4
	or	a1,a1,s3
	xor	a3,a3,t2
	xor	a2,a2,s0
	add	t6,a0,t6
	add	t5,a1,t5
	slli	s5,a3,7
	slli	s2,a2,7
	xor	a4,t6,a4
	xor	t1,t5,t1
	srli	a3,a3,25
	srli	a2,a2,25
	or	a3,a3,s5
	or	a2,a2,s2
	slli	s5,a4,16
	slli	s4,t1,16
	srli	a4,a4,16
	srli	t1,t1,16
	add	t4,a2,t4
	add	t3,t3,a3
	or	a4,a4,s5
	or	t1,t1,s4
	xor	a7,t4,a7
	xor	a6,t3,a6
	add	s1,a4,s1
	add	s0,t1,s0
	slli	s3,a7,16
	slli	s2,a6,16
	xor	a0,s1,a0
	xor	a1,s0,a1
	srli	a7,a7,16
	srli	a6,a6,16
	or	a7,a7,s3
	or	a6,a6,s2
	slli	s5,a0,12
	slli	s4,a1,12
	srli	a0,a0,20
	srli	a1,a1,20
	add	t2,a7,t2
	add	t0,a6,t0
	or	a0,a0,s5
	or	a1,a1,s4
	xor	a2,t2,a2
	xor	a3,t0,a3
	add	t6,t6,a0
	add	t5,t5,a1
	slli	s3,a2,12
	slli	s2,a3,12
	xor	a4,a4,t6
	xor	t1,t1,t5
	srli	a2,a2,20
	srli	a3,a3,20
	or	a2,a2,s3
	or	a3,a3,s2
	slli	s5,a4,8
	slli	s4,t1,8
	srli	a4,a4,24
	srli	t1,t1,24
	add	t4,t4,a2
	add	t3,t3,a3
	or	a4,a4,s5
	or	t1,t1,s4
	add	s1,s1,a4
	add	s0,s0,t1
	xor	a7,a7,t4
	xor	a6,a6,t3
	slli	s3,a7,8
	slli	s2,a6,8
	xor	a0,a0,s1
	xor	a1,a1,s0
	srli	a7,a7,24
	srli	a6,a6,24
	or	a7,a7,s3
	or	a6,a6,s2
	slli	s5,a0,7
	slli	s4,a1,7
	srli	a0,a0,25
	srli	a1,a1,25
	add	t2,t2,a7
	add	t0,t0,a6
	or	a0,s5,a0
	or	a1,s4,a1
	xor	a2,a2,t2
	xor	a3,a3,t0
	sw	s1,40(a5)
	sw	s0,44(a5)
	sw	t6,0(a5)
	sw	a4,60(a5)
	sw	a0,20(a5)
	sw	t5,4(a5)
	sw	t1,48(a5)
	sw	a1,24(a5)
	sw	t4,8(a5)
	sw	a7,52(a5)
	sw	t2,32(a5)
	slli	s3,a2,7
	slli	s2,a3,7
	lw	s0,28(sp)
	srli	a2,a2,25
	srli	a3,a3,25
	or	a2,s3,a2
	or	a3,s2,a3
	sw	a2,28(a5)
	sw	t3,12(a5)
	sw	a6,56(a5)
	sw	t0,36(a5)
	sw	a3,16(a5)
	lw	s1,24(sp)
	lw	s2,20(sp)
	lw	s3,16(sp)
	lw	s4,12(sp)
	lw	s5,8(sp)
	addi	sp,sp,32
	jr	ra
	.size	double_round.constprop.0, .-double_round.constprop.0
	.align	2
	.globl	Hacl_Impl_Chacha20_chacha20_init
	.type	Hacl_Impl_Chacha20_chacha20_init, @function
Hacl_Impl_Chacha20_chacha20_init:
	li	a5,1634762752
	addi	a5,a5,-1947
	sw	a5,0(a0)
	li	a5,857759744
	addi	a5,a5,1134
	sw	a5,4(a0)
	li	a5,2036477952
	addi	a5,a5,-718
	sw	a5,8(a0)
	li	a5,1797283840
	addi	a5,a5,1396
	sw	a5,12(a0)
	lui	t4,%hi(.LANCHOR0)
	lui	a5,%hi(.LANCHOR0+64)
	addi	a4,a0,16
	addi	t5,a1,32
	addi	t4,t4,%lo(.LANCHOR0)
	addi	a5,a5,%lo(.LANCHOR0+64)
.L5:
	lbu	a6,3(a1)
	lbu	t3,0(a1)
	lbu	t1,1(a1)
	lbu	a7,2(a1)
	sb	t3,0(a5)
	sb	t1,1(a5)
	sb	a7,2(a5)
	sb	a6,3(a5)
	lw	a6,64(t4)
	addi	a1,a1,4
	addi	a4,a4,4
	sw	a6,-4(a4)
	bne	t5,a1,.L5
	sw	a3,48(a0)
	addi	a7,a2,12
	addi	a0,a0,52
.L6:
	lbu	a4,3(a2)
	lbu	a6,0(a2)
	lbu	a1,1(a2)
	lbu	a3,2(a2)
	sb	a6,0(a5)
	sb	a1,1(a5)
	sb	a3,2(a5)
	sb	a4,3(a5)
	lw	a4,64(t4)
	addi	a2,a2,4
	addi	a0,a0,4
	sw	a4,-4(a0)
	bne	a2,a7,.L6
	ret
	.size	Hacl_Impl_Chacha20_chacha20_init, .-Hacl_Impl_Chacha20_chacha20_init
	.align	2
	.globl	Hacl_Impl_Chacha20_chacha20_encrypt_block
	.type	Hacl_Impl_Chacha20_chacha20_encrypt_block, @function
Hacl_Impl_Chacha20_chacha20_encrypt_block:
	addi	sp,sp,-48
	sw	s2,32(sp)
	lui	s2,%hi(.LANCHOR0)
	sw	s1,36(sp)
	sw	s3,28(sp)
	sw	s4,24(sp)
	mv	s3,a2
	mv	s4,a0
	li	a2,64
	mv	s1,a1
	mv	a1,a0
	addi	a0,s2,%lo(.LANCHOR0)
	sw	ra,44(sp)
	sw	s0,40(sp)
	sw	s5,20(sp)
	mv	s0,a3
	addi	s5,s2,%lo(.LANCHOR0)
	call	memcpy
	lw	a5,48(s5)
	add	a5,a5,s3
	sw	a5,48(s5)
	call	double_round.constprop.0
	call	double_round.constprop.0
	call	double_round.constprop.0
	call	double_round.constprop.0
	call	double_round.constprop.0
	call	double_round.constprop.0
	call	double_round.constprop.0
	call	double_round.constprop.0
	call	double_round.constprop.0
	call	double_round.constprop.0
	addi	a2,s2,%lo(.LANCHOR0)
	mv	a0,s4
	addi	a4,a2,64
	addi	t4,s2,%lo(.LANCHOR0)
	addi	a5,s2,%lo(.LANCHOR0)
.L10:
	lw	a3,0(a5)
	lw	a1,0(a0)
	addi	a5,a5,4
	addi	a0,a0,4
	add	a3,a3,a1
	sw	a3,-4(a5)
	bne	a4,a5,.L10
	lw	a5,48(t4)
	addi	a0,t4,68
	mv	a3,s0
	add	a5,a5,s3
	sw	a5,48(t4)
	addi	a6,t4,132
	mv	a5,a0
.L11:
	lbu	a1,3(a3)
	lbu	t3,0(a3)
	lbu	t1,1(a3)
	lbu	a7,2(a3)
	sb	t3,0(a4)
	sb	t1,1(a4)
	sb	a7,2(a4)
	sb	a1,3(a4)
	lw	a1,64(t4)
	addi	a5,a5,4
	addi	a3,a3,4
	sw	a1,-4(a5)
	bne	a5,a6,.L11
	mv	a5,a0
.L12:
	lw	a4,0(a5)
	lw	a3,0(a2)
	addi	a5,a5,4
	addi	a2,a2,4
	xor	a4,a4,a3
	sw	a4,-4(a5)
	bne	a5,a6,.L12
	mv	a1,s1
.L13:
	lw	a5,0(a0)
	addi	a0,a0,4
	addi	a1,a1,4
	srli	a2,a5,8
	srli	a3,a5,16
	srli	a4,a5,24
	sb	a2,-3(a1)
	sb	a3,-2(a1)
	sb	a4,-1(a1)
	sb	a5,-4(a1)
	bne	a0,a6,.L13
	lw	ra,44(sp)
	lw	s0,40(sp)
	lw	s1,36(sp)
	lw	s2,32(sp)
	lw	s3,28(sp)
	lw	s4,24(sp)
	lw	s5,20(sp)
	addi	sp,sp,48
	jr	ra
	.size	Hacl_Impl_Chacha20_chacha20_encrypt_block, .-Hacl_Impl_Chacha20_chacha20_encrypt_block
	.align	2
	.globl	Hacl_Impl_Chacha20_chacha20_update
	.type	Hacl_Impl_Chacha20_chacha20_update, @function
Hacl_Impl_Chacha20_chacha20_update:
	addi	sp,sp,-48
	sw	s3,28(sp)
	sw	s4,24(sp)
	sw	s5,20(sp)
	sw	s6,16(sp)
	sw	s7,12(sp)
	sw	s8,8(sp)
	sw	ra,44(sp)
	sw	s0,40(sp)
	sw	s1,36(sp)
	sw	s2,32(sp)
	srli	s4,a1,6
	mv	s5,a1
	mv	s3,a0
	mv	s6,a2
	mv	s7,a3
	andi	s8,a1,63
	beq	s4,zero,.L20
	mv	s2,a2
	mv	s1,a3
	li	s0,0
.L21:
	mv	a3,s1
	mv	a2,s0
	mv	a1,s2
	mv	a0,s3
	addi	s0,s0,1
	call	Hacl_Impl_Chacha20_chacha20_encrypt_block
	addi	s2,s2,64
	addi	s1,s1,64
	bne	s4,s0,.L21
.L20:
	bne	s8,zero,.L28
	lw	ra,44(sp)
	lw	s0,40(sp)
	lw	s1,36(sp)
	lw	s2,32(sp)
	lw	s3,28(sp)
	lw	s4,24(sp)
	lw	s5,20(sp)
	lw	s6,16(sp)
	lw	s7,12(sp)
	lw	s8,8(sp)
	addi	sp,sp,48
	jr	ra
.L28:
	lui	s0,%hi(.LANCHOR0+132)
	addi	s0,s0,%lo(.LANCHOR0+132)
	andi	s5,s5,-64
	add	a1,s7,s5
	mv	a2,s8
	mv	a0,s0
	call	memcpy
	mv	a2,s4
	mv	a1,s0
	mv	a0,s3
	mv	a3,s0
	call	Hacl_Impl_Chacha20_chacha20_encrypt_block
	add	s6,s6,s5
	mv	a1,s0
	lw	s0,40(sp)
	lw	ra,44(sp)
	lw	s1,36(sp)
	lw	s2,32(sp)
	lw	s3,28(sp)
	lw	s4,24(sp)
	lw	s5,20(sp)
	lw	s7,12(sp)
	mv	a2,s8
	mv	a0,s6
	lw	s8,8(sp)
	lw	s6,16(sp)
	addi	sp,sp,48
	tail	memcpy
	.size	Hacl_Impl_Chacha20_chacha20_update, .-Hacl_Impl_Chacha20_chacha20_update
	.align	2
	.globl	Hacl_Chacha20_chacha20_encrypt
	.type	Hacl_Chacha20_chacha20_encrypt, @function
Hacl_Chacha20_chacha20_encrypt:
	addi	sp,sp,-48
	sw	s5,20(sp)
	sw	s6,16(sp)
	mv	s5,a2
	lui	s6,%hi(.LANCHOR0)
	li	a2,1634762752
	addi	s6,s6,%lo(.LANCHOR0)
	addi	a2,a2,-1947
	sw	a2,196(s6)
	li	a2,857759744
	addi	a2,a2,1134
	sw	a2,200(s6)
	li	a2,2036477952
	addi	a2,a2,-718
	sw	a2,204(s6)
	li	a2,1797283840
	addi	a2,a2,1396
	lui	a6,%hi(.LANCHOR0+64)
	sw	s3,28(sp)
	sw	s4,24(sp)
	sw	a2,208(s6)
	sw	ra,44(sp)
	sw	s0,40(sp)
	sw	s1,36(sp)
	sw	s2,32(sp)
	sw	s7,12(sp)
	sw	s8,8(sp)
	sw	s9,4(sp)
	mv	s3,a0
	mv	s4,a1
	addi	a2,s6,212
	addi	t3,a3,32
	addi	a6,a6,%lo(.LANCHOR0+64)
.L30:
	lbu	a1,3(a3)
	lbu	t1,0(a3)
	lbu	a7,1(a3)
	lbu	a0,2(a3)
	sb	t1,0(a6)
	sb	a7,1(a6)
	sb	a0,2(a6)
	sb	a1,3(a6)
	lw	a1,64(s6)
	addi	a3,a3,4
	addi	a2,a2,4
	sw	a1,-4(a2)
	bne	t3,a3,.L30
	sw	a5,244(s6)
	addi	a7,a4,12
	addi	a5,s6,248
.L31:
	lbu	a3,3(a4)
	lbu	a0,0(a4)
	lbu	a1,1(a4)
	lbu	a2,2(a4)
	sb	a0,0(a6)
	sb	a1,1(a6)
	sb	a2,2(a6)
	sb	a3,3(a6)
	lw	a3,64(s6)
	addi	a4,a4,4
	addi	a5,a5,4
	sw	a3,-4(a5)
	bne	a4,a7,.L31
	srli	s8,s3,6
	andi	s9,s3,63
	beq	s8,zero,.L32
	lui	s7,%hi(.LANCHOR0+196)
	mv	s2,s4
	mv	s1,s5
	li	s0,0
	addi	s7,s7,%lo(.LANCHOR0+196)
.L33:
	mv	a3,s1
	mv	a2,s0
	mv	a1,s2
	mv	a0,s7
	addi	s0,s0,1
	call	Hacl_Impl_Chacha20_chacha20_encrypt_block
	addi	s2,s2,64
	addi	s1,s1,64
	bne	s8,s0,.L33
.L32:
	bne	s9,zero,.L42
	lw	ra,44(sp)
	lw	s0,40(sp)
	lw	s1,36(sp)
	lw	s2,32(sp)
	lw	s3,28(sp)
	lw	s4,24(sp)
	lw	s5,20(sp)
	lw	s6,16(sp)
	lw	s7,12(sp)
	lw	s8,8(sp)
	lw	s9,4(sp)
	addi	sp,sp,48
	jr	ra
.L42:
	addi	s0,s6,132
	andi	s3,s3,-64
	add	a1,s5,s3
	mv	a2,s9
	mv	a0,s0
	call	memcpy
	mv	a2,s8
	mv	a1,s0
	addi	a0,s6,196
	mv	a3,s0
	call	Hacl_Impl_Chacha20_chacha20_encrypt_block
	add	s4,s4,s3
	mv	a1,s0
	lw	s0,40(sp)
	lw	ra,44(sp)
	lw	s1,36(sp)
	lw	s2,32(sp)
	lw	s3,28(sp)
	lw	s5,20(sp)
	lw	s6,16(sp)
	lw	s7,12(sp)
	lw	s8,8(sp)
	mv	a2,s9
	mv	a0,s4
	lw	s9,4(sp)
	lw	s4,24(sp)
	addi	sp,sp,48
	tail	memcpy
	.size	Hacl_Chacha20_chacha20_encrypt, .-Hacl_Chacha20_chacha20_encrypt
	.align	2
	.globl	Hacl_Chacha20_chacha20_decrypt
	.type	Hacl_Chacha20_chacha20_decrypt, @function
Hacl_Chacha20_chacha20_decrypt:
	addi	sp,sp,-48
	sw	s5,20(sp)
	sw	s6,16(sp)
	mv	s5,a2
	lui	s6,%hi(.LANCHOR0)
	li	a2,1634762752
	addi	s6,s6,%lo(.LANCHOR0)
	addi	a2,a2,-1947
	sw	a2,260(s6)
	li	a2,857759744
	addi	a2,a2,1134
	sw	a2,264(s6)
	li	a2,2036477952
	addi	a2,a2,-718
	sw	a2,268(s6)
	li	a2,1797283840
	addi	a2,a2,1396
	lui	a6,%hi(.LANCHOR0+64)
	sw	s3,28(sp)
	sw	s4,24(sp)
	sw	a2,272(s6)
	sw	ra,44(sp)
	sw	s0,40(sp)
	sw	s1,36(sp)
	sw	s2,32(sp)
	sw	s7,12(sp)
	sw	s8,8(sp)
	sw	s9,4(sp)
	mv	s3,a0
	mv	s4,a1
	addi	a2,s6,276
	addi	t3,a3,32
	addi	a6,a6,%lo(.LANCHOR0+64)
.L44:
	lbu	a1,3(a3)
	lbu	t1,0(a3)
	lbu	a7,1(a3)
	lbu	a0,2(a3)
	sb	t1,0(a6)
	sb	a7,1(a6)
	sb	a0,2(a6)
	sb	a1,3(a6)
	lw	a1,64(s6)
	addi	a3,a3,4
	addi	a2,a2,4
	sw	a1,-4(a2)
	bne	t3,a3,.L44
	sw	a5,308(s6)
	addi	a7,a4,12
	addi	a5,s6,312
.L45:
	lbu	a3,3(a4)
	lbu	a0,0(a4)
	lbu	a1,1(a4)
	lbu	a2,2(a4)
	sb	a0,0(a6)
	sb	a1,1(a6)
	sb	a2,2(a6)
	sb	a3,3(a6)
	lw	a3,64(s6)
	addi	a4,a4,4
	addi	a5,a5,4
	sw	a3,-4(a5)
	bne	a4,a7,.L45
	srli	s8,s3,6
	andi	s9,s3,63
	beq	s8,zero,.L46
	lui	s7,%hi(.LANCHOR0+260)
	mv	s2,s4
	mv	s1,s5
	li	s0,0
	addi	s7,s7,%lo(.LANCHOR0+260)
.L47:
	mv	a3,s1
	mv	a2,s0
	mv	a1,s2
	mv	a0,s7
	addi	s0,s0,1
	call	Hacl_Impl_Chacha20_chacha20_encrypt_block
	addi	s2,s2,64
	addi	s1,s1,64
	bne	s8,s0,.L47
.L46:
	bne	s9,zero,.L56
	lw	ra,44(sp)
	lw	s0,40(sp)
	lw	s1,36(sp)
	lw	s2,32(sp)
	lw	s3,28(sp)
	lw	s4,24(sp)
	lw	s5,20(sp)
	lw	s6,16(sp)
	lw	s7,12(sp)
	lw	s8,8(sp)
	lw	s9,4(sp)
	addi	sp,sp,48
	jr	ra
.L56:
	addi	s0,s6,132
	andi	s3,s3,-64
	add	a1,s5,s3
	mv	a2,s9
	mv	a0,s0
	call	memcpy
	mv	a2,s8
	mv	a1,s0
	addi	a0,s6,260
	mv	a3,s0
	call	Hacl_Impl_Chacha20_chacha20_encrypt_block
	add	s4,s4,s3
	mv	a1,s0
	lw	s0,40(sp)
	lw	ra,44(sp)
	lw	s1,36(sp)
	lw	s2,32(sp)
	lw	s3,28(sp)
	lw	s5,20(sp)
	lw	s6,16(sp)
	lw	s7,12(sp)
	lw	s8,8(sp)
	mv	a2,s9
	mv	a0,s4
	lw	s9,4(sp)
	lw	s4,24(sp)
	addi	sp,sp,48
	tail	memcpy
	.size	Hacl_Chacha20_chacha20_decrypt, .-Hacl_Chacha20_chacha20_decrypt
	.globl	Hacl_Impl_Chacha20_Vec_chacha20_constants
	.section	.rodata
	.align	2
	.type	Hacl_Impl_Chacha20_Vec_chacha20_constants, @object
	.size	Hacl_Impl_Chacha20_Vec_chacha20_constants, 16
Hacl_Impl_Chacha20_Vec_chacha20_constants:
	.word	1634760805
	.word	857760878
	.word	2036477234
	.word	1797285236
	.section	.secret,"aw"
	.align	2
	.set	.LANCHOR0,. + 0
	.type	k.8, @object
	.size	k.8, 64
k.8:
	.zero	64
	.type	x.41, @object
	.size	x.41, 4
x.41:
	.zero	4
	.type	bl.7, @object
	.size	bl.7, 64
bl.7:
	.zero	64
	.type	plain.2, @object
	.size	plain.2, 64
plain.2:
	.zero	64
	.type	ctx.1, @object
	.size	ctx.1, 64
ctx.1:
	.zero	64
	.type	ctx.0, @object
	.size	ctx.0, 64
ctx.0:
	.zero	64
	.ident	"GCC: (GNU) 11.1.0"
